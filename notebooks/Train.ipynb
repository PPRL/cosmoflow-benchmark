{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Let's play with loading the dataset using `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_data(sample_proto):\n",
    "    parsed_example = tf.parse_single_example(\n",
    "        sample_proto,\n",
    "        features = {'3Dmap': tf.FixedLenFeature([], tf.string),\n",
    "                    'unitPar': tf.FixedLenFeature([], tf.string),\n",
    "                    'physPar': tf.FixedLenFeature([], tf.string)}\n",
    "    )\n",
    "\n",
    "    # Decode the data and normalize\n",
    "    data = tf.decode_raw(parsed_example['3Dmap'], tf.float32)    \n",
    "    data = tf.reshape(data, [128, 128, 128, 1])\n",
    "    #data = tf.reshape(data, [128, 128, 128, 4])[:,:,:,0:1]\n",
    "    data /= (tf.reduce_sum(data) / 128**3)\n",
    "    \n",
    "    # Decode the targets and normalize\n",
    "    label = tf.decode_raw(parsed_example['unitPar'], tf.float32)\n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://portal.nersc.gov/project/m3363/cosmoUniverse_2018_10_3parA/cosmoUniverse_2018_10_3parA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '/project/projectdirs/m3363/www/cosmoUniverse_2019_02_4parE/dim128_cube_nT4'\n",
    "data_dir = '/project/projectdirs/m3363/www/cosmoUniverse_2018_10_3parA/dim128_cube'\n",
    "#data_dir = '/global/cscratch1/sd/djbard/cosmoML/data-3param/13000-2xDupe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_files = None\n",
    "samples_per_file = 16\n",
    "input_shape = (128, 128, 128, 1)\n",
    "target_size = 3\n",
    "\n",
    "batch_size = 8\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = data_dir #os.path.join(data_dir, 'train')\n",
    "train_files = [os.path.join(train_data_dir, f)\n",
    "               for f in os.listdir(train_data_dir)\n",
    "               if f.endswith('tfrecords')][:n_train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 68480 training samples in 4280 TFRecord files\n"
     ]
    }
   ],
   "source": [
    "n_train_files = len(train_files)\n",
    "n_train = n_train_files * samples_per_file\n",
    "print('Loaded %i training samples in %i TFRecord files' % (n_train, n_train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the data pipeline\n",
    "train_dataset = (\n",
    "    tf.data.TFRecordDataset(filenames=train_files)\n",
    "    .map(_parse_data)\n",
    "    .batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_iter = train_dataset.make_one_shot_iterator()\n",
    "next_element = train_iter.get_next()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(n_train_files):\n",
    "    if (i%100) == 0: print(i)\n",
    "    sess.run(next_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.13.1-py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.13.1-py36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.13.1-py36/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Conv3D(16, kernel_size=3, padding='same', input_shape=input_shape))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.AvgPool3D(pool_size=2))\n",
    "\n",
    "model.add(layers.Conv3D(32, kernel_size=3, padding='same'))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.AvgPool3D(pool_size=2))\n",
    "\n",
    "model.add(layers.Conv3D(64, kernel_size=3, padding='same'))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.AvgPool3D(pool_size=2))\n",
    "\n",
    "model.add(layers.Conv3D(128, kernel_size=3, padding='same'))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.AvgPool3D(pool_size=2))\n",
    "\n",
    "model.add(layers.Conv3D(256, kernel_size=3, padding='same'))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.AvgPool3D(pool_size=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LeakyReLU())\n",
    "\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.LeakyReLU())\n",
    "\n",
    "model.add(layers.Dense(target_size))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 128, 128, 128, 16) 448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 128, 16) 0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 64, 64, 64, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 64, 64, 64, 32)    13856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 32, 32, 32, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 32, 32, 32, 64)    55360     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d_2 (Average (None, 16, 16, 16, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 16, 16, 16, 128)   221312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d_3 (Average (None, 8, 8, 8, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 8, 8, 8, 256)      884992    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d_4 (Average (None, 4, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              16778240  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 18,480,547\n",
      "Trainable params: 18,480,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = n_train // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.13.1-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "3822/8560 [============>.................] - ETA: 12:16 - loss: 0.3351 - mean_absolute_error: 0.4099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.26377844097153674,\n",
       "  3.0815238431254296e-05,\n",
       "  3.599911031688586e-09,\n",
       "  4.2055035416922733e-13],\n",
       " 'mean_absolute_error': [0.3873832, 0.3873832, 0.3873832, 0.3873832]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-intel(cpu)/1.13.1-py36",
   "language": "python",
   "name": "tensorflow_intel_1.13.1_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
