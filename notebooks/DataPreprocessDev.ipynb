{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data developments\n",
    "\n",
    "For now I'm going to use this notebook to play with the dataset and develop data preprocessing bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/project/projectdirs/m3363/www/cosmoUniverse_2019_05_4parE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21688988  21922619  21997469  22059249\t22098324  22309462\n",
      "21812950  21929749  22021490  22074825\t22118427\n"
     ]
    }
   ],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open one h5 file and inspect contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile = os.path.join(data_dir, '21688988', 'univ_ics_2019-03_a10000668.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/projectdirs/m3363/www/cosmoUniverse_2019_05_4parE/21688988/univ_ics_2019-03_a10000668.hdf5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['full', 'namePar', 'physPar', 'redshifts', 'unitPar']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dfile, mode='r') as f:\n",
    "    print(f.keys())\n",
    "    x = f['full'][:]\n",
    "    y = f['unitPar'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536870912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting universe into cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 512, 512, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(x, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_universe(x, size):\n",
    "    n = x.shape[0] // size\n",
    "    # Loop over each split\n",
    "    for xi in np.split(x, n, axis=0):\n",
    "        for xij in np.split(xi, n, axis=1):\n",
    "            for xijk in np.split(xij, n, axis=2):\n",
    "                yield xijk"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def split_universe(x, size):\n",
    "    \"\"\"Generator function for iterating over the sub-universes\"\"\"\n",
    "    n = x.shape[0] // size\n",
    "    # Loop over each sub-sample index\n",
    "    for i in range(n):\n",
    "        istart, iend = i * size, (i + 1) * size\n",
    "        for j in range(n):\n",
    "            jstart, jend = j * size, (j + 1) * size\n",
    "            for k in range(n):\n",
    "                kstart, kend = k * size, (k + 1) * size\n",
    "                yield x[istart : iend, jstart : jend, kstart : kend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_size = 128\n",
    "sample_shape = (cube_size, cube_size, cube_size, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum: 536870912\n"
     ]
    }
   ],
   "source": [
    "# Example loop over splits, verify the sum\n",
    "total_sum = 0\n",
    "for i, xi in enumerate(split_universe(x, cube_size)):\n",
    "    total_sum += xi.sum()\n",
    "    # Write out a tfrecord here\n",
    "    #print(i, xi.shape)\n",
    "    #break\n",
    "\n",
    "print('Total sum:', total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant documentation/examples:\n",
    "\n",
    "Jan's conversion code: https://bitbucket.org/balewski/cosmoflow/src/2019_TF/IO_Cosmo_TF1_8.py\n",
    "\n",
    "TF tutorial: https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "\n",
    "Another useful tutorial: https://towardsdatascience.com/working-with-tfrecords-and-tf-train-example-36d111b3ff4d\n",
    "\n",
    "There are multiple ways to serialize the tensor.\n",
    "- I could convert the tensor to a bytestring using numpy's `tostring` method, as Jan did, and then make a `BytesList` feature.\n",
    "- I could possibly use `tf.io.serialize_tensor`, but it's not clear. I think with this one the data needs to first be converted to tf Tensor.\n",
    "- I could save the tensor data as float features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.\n",
    "    #if isinstance(value, type(tf.constant(0))):\n",
    "    #    value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(array):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    # Flatten the array\n",
    "    if len(array.shape) > 1:\n",
    "        array = array.flatten()\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as float features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_example = tf.train.Example(\n",
    "    features=tf.train.Features(\n",
    "        feature=dict(x=_float_feature(xi), y=_float_feature(y))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '.'\n",
    "tfr_file = os.path.join(out_dir, os.path.basename(dfile).replace('.hdf5', '.tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_example = tf_example.SerializeToString()\n",
    "\n",
    "with tf.io.TFRecordWriter(tfr_file) as writer:\n",
    "    writer.write(proto_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = dict(\n",
    "    x=tf.io.FixedLenFeature(sample_shape, tf.float32),\n",
    "    y=tf.io.FixedLenFeature([4], tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example = tf.io.parse_single_example(proto_example, features=feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=(128, 128, 128, 4) dtype=float32>,\n",
       " 'y': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=(4,) dtype=float32>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save using numpy tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_example = tf.train.Example(\n",
    "    features=tf.train.Features(\n",
    "        feature=dict(\n",
    "            x=_bytes_feature(xi.tostring()),\n",
    "            y=_float_feature(y)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_file = os.path.join(out_dir, os.path.basename(dfile).replace('.hdf5', '.nps.tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it\n",
    "proto_example = tf_example.SerializeToString()\n",
    "with tf.io.TFRecordWriter(tfr_file) as writer:\n",
    "    writer.write(proto_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it back\n",
    "feature_description = dict(\n",
    "    x=tf.io.FixedLenFeature([], tf.string),\n",
    "    y=tf.io.FixedLenFeature([4], tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example = tf.io.parse_single_example(proto_example, features=feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <tf.Tensor 'ParseSingleExample_1/ParseSingleExample:0' shape=() dtype=string>,\n",
       " 'y': <tf.Tensor 'ParseSingleExample_1/ParseSingleExample:1' shape=(4,) dtype=float32>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9042665\n",
      "[184 125 136 145]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    _x = tf.reshape(tf.decode_raw(parsed_example['x'], tf.int16), xi.shape).eval()\n",
    "    print(_x.sum())\n",
    "    print(_x[0,0].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xi.sum())\n",
    "print(xi[0,0].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(parsed_example['x'].eval()[0,0,0])\n",
    "    print(parsed_example['y'].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9042665.0\n",
      "[184. 125. 136. 145.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    _x = parsed_example['x'].eval()\n",
    "    print(_x.sum())\n",
    "    print(_x[0,0].sum(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v1.15.0-cpu",
   "language": "python",
   "name": "tensorflow_intel_1.15.0_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
